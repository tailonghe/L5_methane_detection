{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba00a02d-86cf-41f1-b0b9-802de5630c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PlumeNet import *\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a967a2-5f2c-4371-9541-be6d8348c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1449 2505\n"
     ]
    }
   ],
   "source": [
    "flist = glob.glob('augmented_labelled_data/pos_labeller_1/*npz')\n",
    "# print(len(flist))\n",
    "diag = [1]*len(flist)\n",
    "\n",
    "import random\n",
    "_flist = glob.glob('augmented_labelled_data/neg_labeller_1/*npz')\n",
    "random.shuffle(_flist)\n",
    "print(len(flist), len(_flist))\n",
    "\n",
    "flist += _flist\n",
    "diag += [0]*len(_flist)\n",
    "\n",
    "filedf = pd.DataFrame({\"path\" : flist, \"diag\": diag}).sample(frac=1).reset_index(drop=True)\n",
    "filedf.to_csv('train_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365fa549-639f-483e-a7d1-1be15ae76683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_name,\n",
    "                        train_history, val_history, \n",
    "                        num_epochs, log_dir):\n",
    "    \"\"\"\n",
    "    Function to plot history of loss function in training\n",
    "    \"\"\"\n",
    "    x = np.arange(num_epochs)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, train_history, label='train dice', lw=3, c=\"springgreen\")\n",
    "    plt.plot(x, val_history, label='validation dice', lw=3, c=\"deeppink\")\n",
    "\n",
    "    plt.title(f\"{model_name}\", fontsize=15)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel(\"Epoch\", fontsize=15)\n",
    "    plt.ylabel(\"DICE\", fontsize=15)\n",
    "\n",
    "    plt.savefig(log_dir+'%s_training.jpg'%model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70759878-35f7-4695-8f62-0562fb503e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, validation, and test data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "subdf, _ = train_test_split(df, stratify=df.diag, test_size=0.50)  # 10% val\n",
    "\n",
    "samplediff = subdf[subdf['diag'] == 0].shape[0] - subdf[subdf['diag'] == 1].shape[0]\n",
    "subdf = subdf.drop(subdf[subdf['diag'] == 0].sample(n=samplediff).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e2aaf-da6a-4605-92ed-694bf1d6cfda",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# directory to save training logs and final model weights\n",
    "log_dir = 'training_logs/'\n",
    "\n",
    "for member in range(0, 20):\n",
    "\n",
    "    modelname = \"PlumeNet_%d\"%member\n",
    "    # Split df into train_df and val_df, p:1449, n:2505\n",
    "    subdf, _ = train_test_split(df, stratify=df.diag, test_size=0.50)  # 10% val\n",
    "    samplediff = subdf[subdf['diag'] == 0].shape[0] - subdf[subdf['diag'] == 1].shape[0]\n",
    "    subdf = subdf.drop(subdf[subdf['diag'] == 0].sample(n=samplediff).index)\n",
    "\n",
    "    lrnow = np.random.uniform(8e-5, 2e-4)\n",
    "    batchnow = int(np.random.uniform(5, 15))\n",
    "    num_ep = int(np.random.uniform(25, 35))\n",
    "\n",
    "    _params = {\n",
    "        'Model name': modelname,\n",
    "        'Learning rate': lrnow,\n",
    "        'Batch size': batchnow,\n",
    "        'Number of epoch': num_ep,\n",
    "    }\n",
    "    print('Hyper params now:')\n",
    "    print('======================')\n",
    "    _fh = open(log_dir+modelname + '_hyper_params.txt','w')\n",
    "    for key in _params.keys():\n",
    "        print(key + ' : ' + str(_params[key]) + \"\\n\")\n",
    "        _fh.write(key + ' : ' + str(_params[key]) + \"\\n\")\n",
    "    _fh.close()\n",
    "    print('======================')\n",
    "\n",
    "\n",
    "    # Split train_df into train_df and val_df\n",
    "    train_df, val_df = train_test_split(subdf, stratify=subdf.diag, test_size=0.15) \n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df  = val_df.reset_index(drop=True)\n",
    "\n",
    "    print('Pos samples: ', subdf[subdf['diag'] == 1].shape[0])\n",
    "    print('Neg samples: ', subdf[subdf['diag'] == 0].shape[0])\n",
    "    print(f\"Train: {train_df.shape} \\nVal: {val_df.shape}\") # \\nTest: {val_df.shape}\n",
    "\n",
    "    # train\n",
    "    train_dataset = PlumeDataset(df=train_df)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batchnow, num_workers=4, shuffle=True)\n",
    "\n",
    "    # val\n",
    "    val_dataset = PlumeDataset(df=val_df)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batchnow, num_workers=4, shuffle=True)\n",
    "\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    pnet_model = PlumeNet(6, 1, n_classes=1).to(device)\n",
    "    # output = pnet_model(torch.randn(1,6,128,128).to(device))\n",
    "    # print(output.shape)\n",
    "    \n",
    "    %time                                                                                               \n",
    "    # Train ResNeXt50\n",
    "    pnet_optimizer = torch.optim.Adam(pnet_model.parameters(), lr=lrnow)\n",
    "    pnet_lh, pnet_th, pnet_vh = train_model(modelname, pnet_model, train_dataloader, val_dataloader, bce_dice_loss, pnet_optimizer, num_ep)\n",
    "\n",
    "\n",
    "    torch.save(pnet_model.state_dict(), log_dir+'%s_weights.h5'%modelname)\n",
    "    np.savez(log_dir+'%s_history.npz'%modelname, loss=pnet_lh, train=pnet_th, valid=pnet_vh)\n",
    "    plot_model_history(\"%s training history\"%modelname, pnet_th, pnet_vh, num_ep, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48d2d4-7661-4425-918e-a5d192ec360b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
